{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from rich import print\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import dspy\n",
    "from dspy import (\n",
    "    Predict,\n",
    "    Signature,\n",
    "    ChainOfThought,\n",
    "    LM,\n",
    "    settings\n",
    ")\n",
    "\n",
    "load_dotenv('./.env')\n",
    "nai_api_key = os.getenv('NAI_API_KEY')\n",
    "nai_url= 'https://ai.nutanix.com/api/v1/chat/completions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Produce the answer. We start with 15 eggs and if 5 are taken out how many are left? Think step by step\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the NAI-API directly to get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashaswi.piplani/Downloads/DSPy-Python/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ai.nutanix.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.9506478309631348</span> seconds\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time taken: \u001b[1;36m2.9506478309631348\u001b[0m seconds\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response from the API:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Response from the API:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'63079776-1546-4a63-8039-d5822a4ae27b'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730271089</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-llama-3-1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'choices'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Let's break it down step by step.\\n\\n1. We start with 15 eggs.\\n2. 5 eggs are taken </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">out.\\n3. To find the number of eggs left, we need to subtract the number of eggs taken out (5) from the initial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of eggs (15).\\n4. 15 - 5 = 10\\n\\nSo, there are 10 eggs left.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content_filter_results'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'hate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'self_harm'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'sexual'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'jailbreak'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'detected'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'profanity'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'detected'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'id'\u001b[0m: \u001b[32m'63079776-1546-4a63-8039-d5822a4ae27b'\u001b[0m,\n",
       "    \u001b[32m'object'\u001b[0m: \u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[32m'created'\u001b[0m: \u001b[1;36m1730271089\u001b[0m,\n",
       "    \u001b[32m'model'\u001b[0m: \u001b[32m'vllm-llama-3-1'\u001b[0m,\n",
       "    \u001b[32m'choices'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m'message'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Let's break it down step by step.\\n\\n1. We start with 15 eggs.\\n2. 5 eggs are taken \u001b[0m\n",
       "\u001b[32mout.\\n3. To find the number of eggs left, we need to subtract the number of eggs taken out \u001b[0m\u001b[32m(\u001b[0m\u001b[32m5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m from the initial \u001b[0m\n",
       "\u001b[32mnumber of eggs \u001b[0m\u001b[32m(\u001b[0m\u001b[32m15\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n4. 15 - 5 = 10\\n\\nSo, there are 10 eggs left.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[32m'content_filter_results'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'hate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'self_harm'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'sexual'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'violence'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'jailbreak'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'detected'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'profanity'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'detected'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m63\u001b[0m,\n",
       "        \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m80\u001b[0m,\n",
       "        \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m143\u001b[0m,\n",
       "        \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m''\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = requests.post(nai_url, \n",
    "                         headers={\n",
    "                                \"Authorization\": f\"Bearer {nai_api_key}\", \n",
    "                                \"accept\": \"application/json\",\n",
    "                                \"Content-Type\": \"application/json\"\n",
    "                            }, \n",
    "                         json={\n",
    "                                \"model\": \"vllm-llama-3-1\",\n",
    "                                \"messages\": [\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f\"{question}\"\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"max_tokens\": 256,\n",
    "                                \"stream\": False\n",
    "                            }, \n",
    "                         verify=False)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time} seconds\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Response from the API:\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Failed with status code: {response.status_code}\")\n",
    "    print(\"Error message:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Let's break it down step by step.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. We start with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> eggs.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> eggs are taken out.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. To find the number of eggs left, we need to subtract the number of eggs taken out <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> from the initial number of\n",
       "eggs <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)</span>.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "\n",
       "So, there are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> eggs left.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Let's break it down step by step.\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. We start with \u001b[1;36m15\u001b[0m eggs.\n",
       "\u001b[1;36m2\u001b[0m. \u001b[1;36m5\u001b[0m eggs are taken out.\n",
       "\u001b[1;36m3\u001b[0m. To find the number of eggs left, we need to subtract the number of eggs taken out \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m from the initial number of\n",
       "eggs \u001b[1m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\u001b[1;36m4\u001b[0m. \u001b[1;36m15\u001b[0m - \u001b[1;36m5\u001b[0m = \u001b[1;36m10\u001b[0m\n",
       "\n",
       "So, there are \u001b[1;36m10\u001b[0m eggs left.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Using the LM class to create a LM object of the model from NAI-API and configuring the same to use for inference via DSPy Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomInferenceEngineModel(LM):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.endpoint_url = nai_url\n",
    "        self.api_key = nai_api_key\n",
    "        self.kwargs = {\n",
    "            \"temperature\": kwargs.get(\"temperature\"),\n",
    "        }\n",
    "        self.cache = None,\n",
    "        self.model_type = \"chat\"\n",
    "        self.model = \"huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "        self.history = []\n",
    "\n",
    "    def predict(self):\n",
    "        headers={\n",
    "                \"Authorization\": f\"Bearer {self.api_key}\", \n",
    "                \"accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "                }\n",
    "            \n",
    "        request_payload = {\n",
    "                            \"model\": \"vllm-llama-3-1\",\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                }\n",
    "                            ],\n",
    "                            \"max_tokens\": 256,\n",
    "                            \"stream\": False,\n",
    "                         }\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.endpoint_url,\n",
    "            json=request_payload,\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        self.history.append({\n",
    "            \"response\": response.json(),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = CustomInferenceEngineModel()\n",
    "settings.lm = my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">First, we start with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> eggs.\n",
       "Then, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> eggs are taken out.\n",
       "To find out how many eggs are left, we subtract <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "So, there are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> eggs left.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "First, we start with \u001b[1;36m15\u001b[0m eggs.\n",
       "Then, \u001b[1;36m5\u001b[0m eggs are taken out.\n",
       "To find out how many eggs are left, we subtract \u001b[1;36m5\u001b[0m from \u001b[1;36m15\u001b[0m.\n",
       "\u001b[1;36m15\u001b[0m - \u001b[1;36m5\u001b[0m = \u001b[1;36m10\u001b[0m\n",
       "So, there are \u001b[1;36m10\u001b[0m eggs left.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_mod = Predict('Question -> Answer')\n",
    "response = pred_mod(Question=question)\n",
    "print(response.Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': None,\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Your input fields are:\\n1. `Question` (str)\\n\\nYour output fields are:\\n1. `Answer` (str)\\n\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## Question ## ]]\\n{Question}\\n\\n[[ ## Answer ## ]]\\n{Answer}\\n\\n[[ ## completed ## ]]\\n\\nIn adhering to this structure, your objective is: \\n        Given the fields `Question`, produce the fields `Answer`.'},\n",
       "   {'role': 'user',\n",
       "    'content': '[[ ## Question ## ]]\\nProduce the answer. We start with 15 eggs and if 5 are taken out how many are left? Think step by step\\n\\nRespond with the corresponding output fields, starting with the field `Answer`, and then ending with the marker for `completed`.'}],\n",
       "  'kwargs': {'temperature': None},\n",
       "  'response': ModelResponse(id='chatcmpl-1b3e44cb-8010-47d1-889a-ade36ea00d19', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## Answer ## ]]\\nFirst, we start with 15 eggs.\\nThen, 5 eggs are taken out.\\nTo find out how many eggs are left, we subtract 5 from 15.\\n15 - 5 = 10\\nSo, there are 10 eggs left.\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None))], created=1730115509, model='meta-llama/Meta-Llama-3.1-8B-Instruct', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=62, prompt_tokens=210, total_tokens=272, completion_tokens_details=None, prompt_tokens_details=None)),\n",
       "  'outputs': ['[[ ## Answer ## ]]\\nFirst, we start with 15 eggs.\\nThen, 5 eggs are taken out.\\nTo find out how many eggs are left, we subtract 5 from 15.\\n15 - 5 = 10\\nSo, there are 10 eggs left.\\n\\n[[ ## completed ## ]]'],\n",
       "  'usage': {'completion_tokens': 62,\n",
       "   'prompt_tokens': 210,\n",
       "   'total_tokens': 272,\n",
       "   'completion_tokens_details': None,\n",
       "   'prompt_tokens_details': None},\n",
       "  'cost': None,\n",
       "  'timestamp': '2024-10-30T12:21:31.499848',\n",
       "  'uuid': 'f21187f0-187f-4b73-9233-04982bded4cb',\n",
       "  'model': 'huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       "  'model_type': 'chat'}]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Developing custom signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import (\n",
    "    InputField,\n",
    "    OutputField\n",
    ")\n",
    "\n",
    "class MultiClass(Signature):\n",
    "    \"\"\"Classify the given data into Address, Human's name, Location, Building, Amount\"\"\"\n",
    "    sentence = InputField(desc=\"Data to be classified\")\n",
    "    data_type = OutputField(desc=\"Falls in one of the catagories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Predict</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiClass</span><span style=\"font-weight: bold\">(</span>sentence -&gt; data_type\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Classify the given data into Address, Human's name, Location, Building, Amount\"</span>\n",
       "    sentence = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Data to be classified'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Sentence:'</span><span style=\"font-weight: bold\">})</span>\n",
       "    data_type = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Falls in one of the catagories'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Data Type:'</span><span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPredict\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mMultiClass\u001b[0m\u001b[1m(\u001b[0msentence -> data_type\n",
       "    \u001b[33minstructions\u001b[0m=\u001b[32m\"Classify\u001b[0m\u001b[32m the given data into Address, Human's name, Location, Building, Amount\"\u001b[0m\n",
       "    sentence = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'desc'\u001b[0m: \u001b[32m'Data to be classified'\u001b[0m, \n",
       "\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'input'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \u001b[32m'Sentence:'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    data_type = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'desc'\u001b[0m: \u001b[32m'Falls in one of the catagories'\u001b[0m, \n",
       "\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'output'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \u001b[32m'Data Type:'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_class = Predict(MultiClass)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Prediction</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">json_output</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\\n  \"Address\": \"123 Main St\",\\n  \"Human\\'s name\": \"John Doe\",\\n  \"Location\": \"New York\",\\n  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Building\": \"Empire State Building\",\\n  \"Amount\": 1000\\n}'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPrediction\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mjson_output\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"Address\": \"123 Main St\",\\n  \"Human\\'s name\": \"John Doe\",\\n  \"Location\": \"New York\",\\n  \u001b[0m\n",
       "\u001b[32m\"Building\": \"Empire State Building\",\\n  \"Amount\": 1000\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_json_data = Predict('required_data -> json_output')\n",
    "\n",
    "prompt = \"Provide one example of Address, Human's name, Location, Building, Amount\"\n",
    "\n",
    "resp = get_json_data(required_data=prompt)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Address': '123 Main St',\n",
       " \"Human's name\": 'John Doe',\n",
       " 'Location': 'New York',\n",
       " 'Building': 'Empire State Building',\n",
       " 'Amount': 1000}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "recd_data = json.loads(resp.json_output)\n",
    "recd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Classifying:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span> Main St\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Classifying:  \u001b[1;36m123\u001b[0m Main St\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output class is:  Address\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output class is:  Address\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Classifying:  John Doe\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Classifying:  John Doe\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output class is:  Human's name\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output class is:  Human's name\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Classifying:  New York\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Classifying:  New York\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output class is:  Location\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output class is:  Location\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Classifying:  Empire State Building\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Classifying:  Empire State Building\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output class is:  Building\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output class is:  Building\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Classifying:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Classifying:  \u001b[1;36m1000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output class is:  Amount\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output class is:  Amount\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for vals in recd_data.values():\n",
    "    print(\"Classifying: \", vals)\n",
    "    class_resp = pred_class(sentence=vals)\n",
    "    print(\"Output class is: \", class_resp.data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Using ChainOfThought Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"Provide me the top 2 countries with their GDP for last 3 years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"countries\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"United States\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"gdp_2018\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.67</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"gdp_2019\"</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"countries\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m\"name\"\u001b[0m: \u001b[32m\"United States\"\u001b[0m, \u001b[32m\"gdp_2018\"\u001b[0m: \u001b[1;36m22.67\u001b[0m, \u001b[32m\"gdp_2019\"\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"top2Countries\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"country\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"United States\"</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"gdp2020\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.67</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"gdp2021\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.32</span>,\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"top2Countries\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"country\"\u001b[0m: \u001b[32m\"United States\"\u001b[0m,\n",
       "      \u001b[32m\"gdp2020\"\u001b[0m: \u001b[1;36m22.67\u001b[0m,\n",
       "      \u001b[32m\"gdp2021\"\u001b[0m: \u001b[1;36m23.32\u001b[0m,\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_qa = ChainOfThought(\"question -> reasoning, answer_as_json\", n=2)\n",
    "cot_response = cot_qa(question=question2)\n",
    "print(cot_response.completions.answer_as_json[0])\n",
    "print(cot_response.completions.answer_as_json[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-10-30T12:31:59.462540]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer_as_json` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "{answer_as_json}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer_as_json`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Provide me the top 2 countries and their GDP for last 3 years\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `reasoning`, then `answer_as_json`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To provide the top 2 countries and their GDP for the last 3 years, I can use a dataset of global GDP data from 2020, 2021, and 2022. I will first sort the countries by their 2022 GDP and then provide the top 2 countries along with their GDP for the last 3 years.\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "[\n",
      "  {\"country\": \"United States\", \"2020\": 22.67\u001b[0m\n",
      "\n",
      "\u001b[31m \t (and 1 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-10-30T12:32:01.173499]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer_as_json` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "{answer_as_json}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer_as_json`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Provide me the top 2 countries and their GDP for last 3 years\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `reasoning`, then `answer_as_json`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To provide the top 2 countries and their GDP for the last 3 years, I can use a dataset of global GDP data from 2020, 2021, and 2022. I will first sort the countries by their 2022 GDP and then provide the top 2 countries along with their GDP for the last 3 years.\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "[\n",
      "  {\"country\": \"United States\", \"2020\": 22.67\u001b[0m\n",
      "\n",
      "\u001b[31m \t (and 1 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2024-10-30T12:32:58.663622]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer_as_json` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "{answer_as_json}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `reasoning`, `answer_as_json`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Provide me the top 2 countries with their GDP for last 3 years\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `reasoning`, then `answer_as_json`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To answer this question, I will use the World Bank's World Development Indicators dataset, which provides a comprehensive collection of development data on various countries around the world. I will filter the data to get the top 2 countries with their GDP for the last 3 years.\n",
      "\n",
      "[[ ## answer_as_json ## ]]\n",
      "{\n",
      "    \"countries\": [\n",
      "        {\"name\": \"United States\", \"gdp_2018\": 22.67, \"gdp_2019\":\u001b[0m\n",
      "\n",
      "\u001b[31m \t (and 1 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_model.inspect_history(n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
